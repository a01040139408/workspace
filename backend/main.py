from fastapi import FastAPI, Query, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from database.crud import save_article, get_all_articles
from pydantic import BaseModel
from news_scraper import get_top_news, get_article_image
try:
    from gpt_processor import summarize_news, discuss_news, respond_to_opinion
except ImportError:
    from gpt_processor import summarize_news, discuss_news, respond_to_opinion
import urllib.parse

import requests
from bs4 import BeautifulSoup
import random

app = FastAPI()

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost", "http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë‰´ìŠ¤ë³„ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥
conversation_history = {}

class ArticleData(BaseModel):
    title: str
    summary: str
    discussion_point1: str
    discussion_point2: str
    question1: str
    question2: str
    full_discussion: str

# ê¸°ì¡´ ì „ì²´ ë‰´ìŠ¤ ì—”ë“œí¬ì¸íŠ¸ (ë³€ê²½ ì—†ìŒ)
@app.get("/news")
async def fetch_news():
    news = get_top_news()
    return {"news": news}

# ì¹´í…Œê³ ë¦¬ë³„ ë‰´ìŠ¤ í¬ë¡¤ë§ì„ ìœ„í•œ ì„¤ì • ë° í•¨ìˆ˜ (ì´ë¯¸ì§€ í¬í•¨)
NAVER_NEWS_CATEGORIES = {
    "ranking": "https://news.naver.com/main/ranking/popularDay.naver",
    "politics": "https://news.naver.com/section/100",
    "economy": "https://news.naver.com/section/101",
    "society": "https://news.naver.com/section/102",
    "life": "https://news.naver.com/section/103",
    "it": "https://news.naver.com/section/105",
    "world": "https://news.naver.com/section/104",
}

def fetch_category_news(category: str):
    url = NAVER_NEWS_CATEGORIES.get(category)
    if not url:
        raise ValueError("ì˜¬ë°”ë¥´ì§€ ì•Šì€ ì¹´í…Œê³ ë¦¬")
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36"
    }
    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        raise HTTPException(status_code=500, detail="ë„¤ì´ë²„ ë‰´ìŠ¤ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨")
    soup = BeautifulSoup(response.text, "html.parser")
    news_list = []
    if category == "ranking":
        news_items = soup.select(".rankingnews_list li a.list_title")
    else:
        news_items = soup.select("ul.sa_list li a.sa_text_title")
    if not news_items:
        raise HTTPException(status_code=404, detail=f"{category} ì¹´í…Œê³ ë¦¬ì—ì„œ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
    sampled_news = random.sample(news_items, min(7, len(news_items)))
    for item in sampled_news:
        title = item.text.strip()
        link = item["href"]
        if not link.startswith("http"):
            link = "https://news.naver.com" + link
        image_url = get_article_image(link)
        news_list.append({"title": title, "url": link, "image": image_url})
    return news_list

@app.get("/news/{category}")
async def get_news_by_category(category: str):
    try:
        news = fetch_category_news(category)
        return {"category": category, "news": news}
    except ValueError:
        raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ì¹´í…Œê³ ë¦¬ ìš”ì²­")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/summarize")
async def fetch_summary(title: str, url: str):
    summary = summarize_news(title, url)
    return {"title": title, "url": url, "summary": summary}

@app.get("/discuss")
async def fetch_discussion(title: str, url: str):
    discussion_points = discuss_news(title, url)
    return {"title": title, "url": url, "discussion_points": discussion_points}

@app.get("/respond")
async def fetch_response(title: str = Query(...), url: str = Query(...), opinion: str = Query(...)):
    title = urllib.parse.unquote(title)
    url = urllib.parse.unquote(url)
    opinion = urllib.parse.unquote(opinion)
    if (title, url) not in conversation_history:
        conversation_history[(title, url)] = []
    ai_response = respond_to_opinion(title, url, opinion)
    conversation_history[(title, url)].append({"user": opinion, "ai": ai_response})
    print(f"âœ… ëŒ€í™” íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸: {conversation_history[(title, url)]}")
    return {
        "title": title,
        "url": url,
        "opinion": opinion,
        "ai_response": ai_response,
        "conversation_history": conversation_history[(title, url)]
    }

@app.post("/save_article/")
def save_article_api(article: ArticleData):
    """ğŸŸ¨ğŸŸ¨ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ DBì— ì €ì¥í•˜ëŠ” API ì—”ë“œí¬ì¸íŠ¸ ğŸŸ¨ğŸŸ¨"""
    save_article(
        article.title, 
        article.summary, 
        article.discussion_point1, 
        article.discussion_point2, 
        article.question1, 
        article.question2, 
        article.full_discussion
    )
    return {"message": "ê¸°ì‚¬ ì €ì¥ ì„±ê³µ!"}

@app.get("/articles/")
def get_articles():
    """ğŸŸ¨ğŸŸ¨ ì €ì¥ëœ ê¸°ì‚¬ ëª©ë¡ ì¡°íšŒ API ğŸŸ¨ğŸŸ¨"""
    articles = get_all_articles()
    return {"articles": articles}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
